# -*- coding: utf-8 -*-
"""10-2 연습문제.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a7A-tfvhNcsFUzVmp9_lYUECAGlF35Y3
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense    #어떤 층을 사용할지

x1 = np.array([5,7,1,2,4,4,9,5,9,3])
x2 = np.array([0,-7,13,-6,3,0,-1,7,2,-9])
x = np.column_stack((x1,x2))   #길이가 10인 백터를 열방향으로 합치는 것
y = np.array([3,1,11,10,6,4,5,1,3,9]).reshape(10,1)  #벡터로 만든 후, reshape을 통해 10,1행렬로 만들어줌
print('x데이터의 형태 : ', x.shape)
print('y데이터의 형태 : ', y.shape)

"""* 레이어가 3개인 """

#layer을 3개, 은닉층2개
model = Sequential()
model.add(Dense(units=3, activation='relu', input_dim = 2))    #input_dim=x.shape[1]
model.add(Dense(units=2, activation='relu'))   
model.add(Dense(units=1, activation='linear')) #activation은 자기 자신으로 했기 때문에 linear
model.summary()

model.compile(loss='mse', metrics=['mae', 'mse'])        #비용함수 지정,  y값이 실수값일 때 mse(평균제곱오차 : 실제y와 예측y의 차이의 제곱의 합) : 평균제곱오차를 최소화하는 방향으로 파라미터 추정할거임
model.fit(x,y,epochs = 30000, verbose = 0)

model.weights

model.predict(x)

"""
## 활설화 함수가 필요한 이유: 비선형 연산임

미리지정 
sigmoid 
tanhsms(-1,1)사이
relu : 별말없으면 이거 쓰셈ㅁㅁㅁㅁ


0. 활성화 왜 해야 함?
: 비선형함수를 쓰는 효과가 있나? , 선형함수로 쓰는 것은 2차함수식으로 되어있는 자료를 분류할 수가 없다.   


1. but,(1)relu라는 함수를 쓰면서 레이어 한층이 올라갈 때 선형변환 후 활성화를 하면서 음수쪽에 있는 것은 0으로 붙게 되고, 선형적으로 처리할 수 있게 만들어 줌

2. (2) 선형변화를 2번 한 것은 한개의 선형결합으로 가능하기 때문에 은닉칭을 하는 이유가 없음. 따라서, 은닉층에서 항등함수는 사용하지 않음. 마지막 출력층에서 사용






3. => 손실함수와 비용함수(EX.mse)를 정의하고.  비용함수를 최소화하는 값을 씀
4. 비용함수 ex : 평균제곱오차(mse, 연속형일때). 이진교차엔트로피(단순로지스틱회귀) , 교차엔트로피 (범주형 개수가 3개 이상일 때, ex).  강아지, 고양이 등)

"""